\begin{singlespacing}
\chapter{Searches in ATLAS}
\label{chapter:searches}
%
\begin{epigraphs}
\qitem{%
One way is to make it so simple that there are \emph{obviously} no deficiencies
and the other way is to make it so complicated that there are no \emph{obvious}
deficiencies.%
}%
{Tony~Hoare,
\textit{The Emperorâ€™s Old Clothes},
1981~\cite{hoare2007emperor}}
\end{epigraphs}
\end{singlespacing}

Our task in scientific data analysis is to distil an informative
message from data and to report that message to the wider community.
From any given data there are many possible messages that could be extracted,
and those messages will have different values to different recipients of our
messages --- our data analysis is not an automatic process, but a result
of many judgements that are informed by theory, convention, and intuition.

To clarify our later description of the $\twoljets$ search in
Chapter~\ref{chapter:2ljets}, this chapter introduces the basic theory and
practice of data analysis and its manifestations in the \atlas\ SUSY community.

Theoretical data analysis in the tightly coupled fields of probability theory
and decision theory is introduced in Section~\ref{sec:searces_data_analysis}.
An attempted alternative formulation, frequentist theory, is discussed in
Section~\ref{sec:searches_frequentist} for its relevance to our methods.
Standard practice in this field of research does not strictly follow
frequentist methods, but patches up some of their pathologies with modified
approaches that we describe in Section~\ref{sec:searches_practice}.
Searches for Supersymmetric signals in \atlas\ follow a standard strategy for
their data analysis; its procedures, nomenclature, and parametric modelling
are introduced in Section~\ref{sec:searches_searches}.


\section{Data analysis}
\label{sec:searces_data_analysis}
How many jelly beans are in the jar of Figure~\ref{fig:significant_beans}?
Your answer depends not only on what you observe from the figure, but also on
what else you know about cartoon jars of beans, and on what reward is on offer.
Each answer is a decision that depends both on what the possible rewards are,
and on which numbers of beans you subjectively infer to be likely.
We shall return to this example after developing some probability and decision
theory.

\begin{figure}[tp]
\centering
\includegraphics[width=0.25\textwidth]{figures/searches_beans.pdf}
\caption[
How many beans are in the jar?
]{%
How many beans are in the jar? This jar of jelly beans is a vehicle for our
discussion of inference and decision theory.
Please write your guess on this page.
The first correct answer wins a gold star.
}
\label{fig:significant_beans}
\end{figure}

Statistical data analysis suffers from dogma --- prescriptions and recipes that
students are taught to memorize and follow without knowing their reasons or
limitations.
From a standard undergraduate physics education, my experience has been
error propagation formulae,
least squares fitting routines,
chi-squared per degree of freedom,
and myriad statistical tests and confidence intervals.
Many of these are effective approximations, but all also fail if misused
outside of their domain.%
\footnote{%
Multiplicative error propagation is an example.
For $a = \mu_a \pm \sigma_a$ and $b = \mu_b \pm \sigma_b$,
the perturbative approximation is
\(
\widetilde{\sigma}_{ab}
= \mu_a \mu_b \sqrt{\sigma_a^2/\mu_a^2 + \sigma_b^2/\mu_b^2}
% = \sigma_a^2 \mu_b^2 + \sigma_b^2 \mu_a^2
\),
but calculation with their moments derives
\(
\sigma_{ab}
= \sqrt{(\mu_a^2 + \sigma_a^2)(\mu_b^2 + \sigma_b^2) - \mu_a^2\mu_b^2}
% = \sigma_a^2 \mu_b^2 + \sigma_b^2 \mu_a^2 + \sigma_a^2 \sigma_b^2
\)
exactly if independent.
Since $\sigma_{ab}^2 = \widetilde{\sigma}_{ab}^2 + \sigma_a^2 \sigma_b^2$, the
propagation formula works only for small relative errors.
}
All effective methods of data analysis can be derived upwards from the roots of
probability and decision theory, and as elsewhere in physics, by knowing the
derivations we can also know when each approximation should work and when it
needs replacing.

We begin with what probability is: at its most abstract, a probability a
proportion of stuff within a larger whole.
Probabilities useful because proportions have applications, and because they
can be manipulated and interrelated with a linear and intuitive algebra.

\paragraph{Probability, abstract.}
A probability $\prob{b}{a}$ is a number that quantifies the proportion
of $b$ within $a$, and can be expressed as a ratio~\cite{axioms1010038}
\begin{equation}
\label{eqn:searches_prob_ratio}
\prob{b}{a} = \frac{m(b, a)}{m(a)},
\end{equation}
in which $m(x)$ is a measure (a non-negative quantity assigned to its
argument, such as mass of tea in a cup), and the comma `,' means `and'
(logical and or set intersection or any other equivalent operation).
To continue that example, $\prob{b}{a}$ could be a proportion of tea within
a spoon within a cup, where $m(b, a)$ measures the volume of tea in a
teaspoon that is partially submerged in the cup.%
\footnote{%
All probabilities are conditional in this definition; $\probc{b}$ alone does
not exist unless the conditioning information $a$ is implicit from context.%
}

Logic is an important application of probability for which $a$ and $b$ are
interpreted as logical propositions, and
$\prob{b}{a}$ is the degree to which $a$ implies $b$, with the limiting cases
that $\prob{b}{a} = 1$ when $a$ implies $b$ and $\prob{b}{a} = 0$ when $a$
disproves $b$.
Indeed Cox's theorem derives the laws of probability by requiring compatibility
with Boolean logic~\cite{
cox1946probability,
cox1961algebra,
garrett1998nand,
jaynes2003probability,
keynes1920treatise
}.
Probability works for logic and it works \emph{for tea, too}.

Two algebraic rules derive from Equation~\ref{eqn:searches_prob_ratio}:
a \textbf{product rule}
\begin{align}
\prob{c, b}{a} &= \prob{c}{b, a}\times \prob{b}{a},
\label{eqn:searches_product_rule}
\intertext{%
that describes nested proportions
(perhaps a spoon within a teacup within a sink),
and a \textbf{sum rule}%
}
\prob{c\vee b}{a} &= \prob{c}{a} + \prob{b}{a} - \prob{c, b}{a},
\label{eqn:searches_sum_rule}
\end{align}
that describes combination in a union $\vee$ that coincides with logical `or'.
The subtraction avoids double-counting of any overlap, and is often avoided by
splitting any problem into orthogonal, or disjoint states.
For disjoint cases with labels $b_i$, normalization therefore requires that
\begin{equation}
\label{eqn:searches_normalization}
\sum_i \prob{b_i}{a} = 1.
\end{equation}
These rules are basic and well known, but we state them here to support the
following statements of how probabilities can be applied for practical
results.%
\footnote{%
The formulation with sums and products is not strictly unique, but all
alternatives are equivalent up to an invertible
transformation~\cite{axioms1010038}.
This choice is usually best because it uses ordinary addition and
multiplication.
In numerical analysis, however, it is often practical to use $\log$
probabilities to avoid overflows outside the range representable by floating
point numbers, thus changing multiplication to addition and addition to
the `$\log$-add-$\exp$' operation.
}

\paragraph{Probability, applied.}
% science snake
Science involves making predictions, testing those predictions against data,
and reporting what is learned from the results.
Various probabilities are involved in this prediction and learning that have
conventional names to communicate what we intend to do with them.
Most important for prediction is a \textbf{likelihood}
\begin{align}
L(a) &= \prob{b}{a} \\
\label{eqn:searches_likelihood}
\intertext{%
that explores the probabilities assigned to a fixed result $b$ from different
contexts $a$, or how well different hypotheses predicted a result.
A likelihood is clearly a probability, but it is not a probability distribution
--- only the left hand argument $b$ forms a normalized distribution.
Alternatively, fixing the context gives a \textbf{prior}%
}
\pi(b) &= \prob{b}{a}
\label{eqn:searches_prior}
\end{align}
for fixed $a$, which is a normalized distribution over disjoint states $b$.

Likelihood and prior are evidently related --- they explore two indices into
the same object, two sides of the same coin, and are assigned by the same
principles.
But they are profoundly different objects that work for different purposes,
and clarity in their distinction will help in our later understanding of
practical methods.
For observed data, we use likelihoods to compare which hypotheses predicted
them better than others, and before observing data we use priors to describe
what data might result from different models to design our experiments.

To illustrate this, consider a histogram that bins event yields in
$\met$, with distributions from background and (supersymmetric) signal samples
overlaid.
Example such histograms are displayed in
Figure~\ref{fig:searches_sig_bkg_prior_likelihood}.
Since these histograms are normalized to unit area, they show prior
probability distributions along the bin axis; there is one prior
for events from each of the background and signal hypotheses.
Priors distribute unit probability explore along the bin axis.
In each bin, however, a likelihood function compares the assignments from
the two hypotheses: signal and background.
Likelihoods explore vertically down the sample axis.

\begin{figure}[tp]
\centering
\includegraphics[width=\textwidth]{figures/searches_sig_bkg_prior_likelihood.pdf}
\caption[
Background and signal prior densities
]{%
Background and signal prior densities in $\eV[G]$ and $\eV[G]^{1/2}$ units.
When changing coordinates, probability mass moves as a fluid of constant total
volume.
In each bin a likelihood function is indexed by the background--signal labels
and is independent of the prior units since the area in each bin is invariant.
}
\label{fig:searches_sig_bkg_prior_likelihood}
\end{figure}

Identical distributions are drawn in two different coordinates
on the left and right of Figure~\ref{fig:searches_sig_bkg_prior_likelihood};
they are identical in content, but differ in appearance because they use the
standard approach of representing each prior distribution as a density.%
\footnote{%
Density is a somewhat misleading term here.
Probability mass does not compress, it moves and redistributes --- it is more
like depth of tea than density of air.%
}
To preserve the area of each bin, which shows its probability mass,
bin heights therefore change to adapt to their widths that change due to the
differing values of $\met$ and $\sqrt{\met}$.

We typically approximate such histograms by Monte Carlo simulation methods,
since simulations do not generate bin indices but event variables.
We connect these concepts with probabilities here.
First, some notation; we have hypotheses $h$ (signal or background),
a parameter $x$ that we histogram ($x = \met$),
and we observe a datum $d$ that datum indexes the histogram bins --- supposing
an event is observed in the overflow bin, it says
$d = `x > 100\,\eV[G]\textrm{'}$.
This observed bin has a likelihood function
\begin{equation}
L(x) = \prob{d}{x, h} = \prob{d}{x} =
\left\{
\begin{matrix}
1 & \textrm{if }~x > 100\,\eV[G], \\
0 & \textrm{otherwise} \\
\end{matrix}
\right.
\end{equation}
that corresponds to Equation~\ref{eqn:searches_likelihood} by
$b \leftarrow d$ and $a \leftarrow `x, h\textrm{'}$,
and simplifies $\prob{d}{x, h} = \prob{d}{x}$ since binning is independent of
hypothesis.
Simulating events from background and signal hypotheses samples from their
respective priors
\begin{equation}
\pi(x) = \prob{x}{h}
\end{equation}
that correspond to Equation~\ref{eqn:searches_prior} by
$b \leftarrow x$ and $a \leftarrow h$.
Although we previously used the same labels $a$ and $b$, those are only
labels --- the words `prior' and `likelihood' state our intent to index into
the left and right arguments respectively.

When we fill a histogram by summing weights of simulated samples, we are
calculating another likelihood over hypotheses $h$ alone, not $`x, h\textrm{'}$
jointly.
To disambiguate the two, we call this abstracted, $x$-independent likelihood
the \textbf{evidence} $Z(h)$ for hypothesis $h$.
We calculate this evidence
\begin{align}
Z
= \prob{d}{h} &= \sum_i L(x_i) \,\pi(x_i) \\
&= \int\! L(x) \,\mathrm{d}\pi(x),
\label{eqn:searches_evidence_integral_measure}
\end{align}
where Equation~\ref{eqn:searches_evidence_integral_measure} is notation for
integrating the likelihood function over the prior measure~\cite{
billingsley2008probability,
skilling2010foundations
}, and relates most closely to our practice of simulating from the model and
counting events that hit the non-zero likelihood in the bin.
We shall shortly derive this identity.
The name `evidence' relates to its application for model comparison.
Supposing we have this one event, did it come from the background or signal
sample?
The answer depends on the signal and background cross-sections in our collider,
but larger evidence for signal does influence any conclusion to move in its
favour.

% posterior
Perhaps we now want to see where in the overflow bin this event landed, and
compare the signal and background distributions there.
This is an inspection of the \textbf{posterior}
\begin{equation}
p(x) = \prob{x}{d, h} = \frac{L(x)\,\pi(x)}{Z},
\end{equation}
which is a prior probability distribution specialized by the data;
it simply uses the likelihood to filter simulated samples
(perhaps in `skimming an ntuple')
and re-normalizes them to a probability distribution within the constraint.

We finally have the four parts of `Bayesian' data analysis:
the two inputs \textbf{likelihood} and \textbf{prior},
and two outputs \textbf{posterior} and \textbf{evidence}.
These relate through Bayes' rule, which is a consequence of the
produce rule of Equation~\ref{eqn:searches_product_rule} and the
commutativity of `and' --- that `$a$ and $b$' is equivalent to
`$b$ and $a$';
the joint probability of data and parameters has two identical
forms, $\prob{d, x}{h}$ and $\prob{x, d}{h}$, that each factor into two
pieces:
\begin{align}
\prob{d}{x, h}\times \prob{x}{h} &= \prob{x}{d, h}\times \prob{d}{h},
\intertext{all of which which we have named:}
\underbrace{L(x)}_\textbf{likelihood}
\times
\overbrace{\pi(x)}^\textbf{prior}
~\,
&=
\overbrace{p(x)}^\textbf{posterior}
\times
\underbrace{Z}_\textbf{evidence}
.
% \textbf{likelihood} \times \textbf{prior}
% &= \textbf{posterior} \times \textbf{evidence} .\nonumber
\end{align}

% likelihood ratio
\begin{equation}
\hphantom{\quad \quad \mid\mid \mathrm{context}}
\frac{\prob{S}{d}}{\prob{B}{d}}
=
\!\!
\underbrace{\frac{\prob{d}{S}}{\prob{d}{B}}}_\textrm{likelihood ratio}
\!\!\times~
\frac{\probc{S}}{\probc{B}}
\quad \quad \mid\mid \mathrm{context}
\end{equation}


Probabilistic learning proceeds as follows:
\begin{enumerate}
\item Predict new data $d$ with probability $\prob{d}{\ldots, h}$.
\item Update your predictions with the observed data to $\prob{x}{d, \ldots, h}$.
\item Go to 1.
\end{enumerate}


% bayes
\TODO{move to connection to frequentist section}
Bayes' theorem is an infamous and necessary result, and it is not seriously
disputed. What has been disputed is whether probability can be applied to
logic, or any application other than the random happenings of events.

% posterior

\paragraph{Probability assignments.}
infamously arbitrary and subjective. This is reality. They are.
Consider this simple mathematical example with two propositions
$a=\textrm{``}x\textrm{ is even''}$ and
$b=\textrm{``}x\textrm{ equals }2\textrm{''}$.
Clearly $\prob{a}{b} = 1$ since $2$ is indeed even.
But what is $\prob{b}{a}$? We don't know. Perhaps one could argue symmetry
across all even numbers, but there are infinitely many of them so that
probability distribution could not be normalized.

\TODO{\ldots}


\paragraph{Decision theory.}


% summary

Figure~\ref{fig:searches_baton_roue_bayes}

\begin{figure}[tp]
\centering
\includegraphics[width=0.65\textwidth]{figures/searches_baton_roue_bayes.jpg}
\caption[
Bayesian analysis produces two outputs: the evidence and posterior
]{%
Bayesian analysis produces two outputs: the
evidence $\prob{d}{h}$ and
posterior $\prob{x}{d,h}$ for hypothesis $h$, data $d$, and parameters $x$.
Posterior-only, semi-Bayesian methods are legitimately criticized because they
do not challenge the hypotheses that assign their priors $\prob{x}{h}$.
Since the evidence is a likelihood function over hypotheses, considering the
evidence can challenge those priors.
\\[0.5em]
Cartoon adapted from ``Baton roue'' by
Corentin~Penloup~\cite{penloup2011baton}.
}
\label{fig:searches_baton_roue_bayes}
\end{figure}


\begin{singlespacing}
\section{Frequentist theory}
\label{sec:searches_frequentist}
\begin{epigraphs}
\qitem{%
Within this theory, statistical methods of great practical usefulness have been
developed, and its statements can and frequently do contribute in a vague way
to the interpretation of data. \ldots%
}%
{John~W.~Pratt,
\textit{Review: Testing Statistical Hypotheses},
1961~\cite{pratt1961testing}}
\end{epigraphs}
\end{singlespacing}

Figure~\ref{fig:searches_significant}

\begin{figure}[tp]
\centering
\includegraphics[width=0.55\textwidth]{figures/searches_significant_shrink.png}
\\
\begin{footnotesize}
`So, uh, we did the green study again and got no link. It was probably a{-}{-}'
\\
`RESEARCH CONFLICTED ON GREEN JELLY BEAN ACNE LINK; MORE~STUDY~RECOMMENDED!'
\end{footnotesize}
\caption[
``Significant'' by Randall~Munroe
]{%
``Significant'' by Randall~Munroe~\cite{xkcd2011significant}.
}
\label{fig:searches_significant}
\end{figure}


\begin{singlespacing}
\section{Post-frequentist practice}
\label{sec:searches_practice}
\begin{epigraphs}
\qitem{%
\ldots\ But this book, by its very excellence, its thoroughness, lucidity and
precision, intensifies my growing feeling that nevertheless the theory is
arbitrary, be it however ``objective,'' and the problems it solves, however
precisely it may solve them, are not even simplified theoretical counterparts
of the real problems to which it is applied.%
}%
{John~W.~Pratt,
\textit{Review: Testing Statistical Hypotheses},
1961~\cite{pratt1961testing}}
\end{epigraphs}
\end{singlespacing}


% significance measures
The ATLAS-recommended significance measure~\cite{atlas_significance} is
\begin{align}
\label{eqn:significance_atlas}
S_\mathrm{\atlas}(n; \mu, \sigma) =~&
\sqrt{2} \times
\mathrm{sign}(n - \mu) \times
\\[0.2em] \nonumber
&
\sqrt{
n\log\left(\frac{n(\mu + \sigma^2)}{\mu^2 + n\sigma^2}\right)
- \frac{\mu^2}{\sigma^2}\log\left(
1 + \frac{\sigma^2(n - \mu)}{\mu(\mu + \sigma^2)}
\right)
}
,
\end{align}
in an appropriate limit where $0\log(0x) = 0$ for the $n=0$ case.


\section{Searches}
\label{sec:searches_searches}
% histograms, CR VR SR, systematics
% histfactory

To model the consequences of these many factors of uncertainty, each factor is
assigned a real-valued parameter which when varied changed the expected yields
in the hisogram bins of the search.
In this way, we form a statistical model which is a function
\begin{equation}
H_{\!f}(\vec \theta) \rightarrow (\vec \mu, \log f)
\end{equation}
from the parameters $\theta$ to Poisson expectations $\vec\mu$ the histogram
bins and a regularization term $\log f$ which is maximized in fitting.

\histfactory~\cite{cranmer2012histfactory}
\pyhf~\cite{heinrich2021pyhf}
\histfitter~\cite{Besjes_2015,baak2015histfitter}


\clearpage

Hello again
